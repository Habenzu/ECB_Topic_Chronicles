{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df3721a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "from typing import List, Tuple, Optional\n",
    "\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "from sklearn.metrics import f1_score, precision_recall_fscore_support, precision_score\n",
    "from tqdm import tqdm\n",
    "from loguru import logger\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from transformers import AutoTokenizer, AutoModel, get_linear_schedule_with_warmup\n",
    "from pathlib import Path\n",
    "\n",
    "MODEL_DIR = Path.cwd() / 'models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2861fcb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# Data utilities\n",
    "# ----------------------------\n",
    "class MultiLabelDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        df: pl.DataFrame,\n",
    "        tokenizer,\n",
    "        n_labels: int,\n",
    "        max_len: int = 512,\n",
    "        chunk_size: Optional[int] = None,\n",
    "        chunk_stride: Optional[int] = None\n",
    "    ):\n",
    "        self.texts = df[\"text\"].to_list()\n",
    "        self.labels_list = df[\"topic_label\"].to_list()\n",
    "        self.n_labels = n_labels\n",
    "        self.tok = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "        # chunking: precompute (doc_idx, chunk_idx) index if chunking enabled\n",
    "        self.use_chunking = bool(chunk_size) and chunk_size > 0\n",
    "        self.chunk_size = chunk_size if self.use_chunking else None\n",
    "        self.chunk_stride = max(0, chunk_stride) if (self.use_chunking and chunk_stride is not None) else 0\n",
    "        if self.use_chunking:\n",
    "            self.doc_chunks = []   # list of dicts returned by tokenizer per doc\n",
    "            self.index = []        # list of (doc_idx, chunk_idx)\n",
    "            for di, t in enumerate(self.texts):\n",
    "                enc = self.tok(\n",
    "                    t,\n",
    "                    truncation=True,\n",
    "                    max_length=self.chunk_size,\n",
    "                    stride=self.chunk_stride,\n",
    "                    return_overflowing_tokens=True,\n",
    "                    padding=False,\n",
    "                )\n",
    "                n = len(enc[\"input_ids\"])\n",
    "                self.doc_chunks.append(enc)\n",
    "                for ci in range(n):\n",
    "                    self.index.append((di, ci))\n",
    "\n",
    "        logger.info(f\"Initialized MultiLabelDataset (chunking={self.use_chunking})\")\n",
    "\n",
    "    def __len__(self):\n",
    "        # NEW (chunking): number of chunks vs. number of docs\n",
    "        return len(self.index) if self.use_chunking else len(self.texts)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        if self.use_chunking:\n",
    "            di, ci = self.index[i]\n",
    "            encs = self.doc_chunks[di]\n",
    "            input_ids = encs[\"input_ids\"][ci]\n",
    "            attention_mask = encs[\"attention_mask\"][ci]\n",
    "            y = torch.zeros(self.n_labels, dtype=torch.float)\n",
    "            for lab in self.labels_list[di]:\n",
    "                if 0 <= lab < self.n_labels:\n",
    "                    y[lab] = 1.0\n",
    "            # include doc_index for later aggregation\n",
    "            return {\"input_ids\": input_ids, \"attention_mask\": attention_mask, \"labels\": y, \"doc_index\": di}\n",
    "        else:\n",
    "            enc = self.tok(self.texts[i], truncation=True, padding=False, max_length=self.max_len)\n",
    "            y = torch.zeros(self.n_labels, dtype=torch.float)\n",
    "            for lab in self.labels_list[i]:\n",
    "                if 0 <= lab < self.n_labels:\n",
    "                    y[lab] = 1.0\n",
    "            return {**enc, \"labels\": y}\n",
    "\n",
    "\n",
    "def collate_pad(batch, pad_id: int):\n",
    "    keys = [\"input_ids\", \"attention_mask\"]\n",
    "    max_len = max(len(b[\"input_ids\"]) for b in batch)\n",
    "    for b in batch:\n",
    "        for k in keys:\n",
    "            pad_len = max_len - len(b[k])\n",
    "            if pad_len > 0:\n",
    "                b[k] = b[k] + ([pad_id] * pad_len)\n",
    "    input_ids = torch.tensor([b[\"input_ids\"] for b in batch], dtype=torch.long)\n",
    "    attn = torch.tensor([b[\"attention_mask\"] for b in batch], dtype=torch.long)\n",
    "    labels = torch.stack([b[\"labels\"] for b in batch])\n",
    "    out = {\"input_ids\": input_ids, \"attention_mask\": attn, \"labels\": labels}\n",
    "\n",
    "    # NEW (chunking): pass through doc_index if present\n",
    "    if \"doc_index\" in batch[0]:\n",
    "        out[\"doc_index\"] = torch.tensor([b[\"doc_index\"] for b in batch], dtype=torch.long)\n",
    "    return out\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Imbalance helpers (unchanged)\n",
    "# ----------------------------\n",
    "def compute_label_stats(labels_list: List[List[int]], n_labels: int) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    counts = np.zeros(n_labels, dtype=np.int64)\n",
    "    for labs in labels_list:\n",
    "        for l in labs:\n",
    "            if 0 <= l < n_labels:\n",
    "                counts[l] += 1\n",
    "    N = len(labels_list)\n",
    "    prevalence = np.clip(counts / max(N, 1), 1e-8, 1 - 1e-8)\n",
    "    return counts, prevalence\n",
    "\n",
    "def make_pos_weights(prevalence: np.ndarray, alpha: float = 0.75, max_w: float = 30.0) -> torch.Tensor:\n",
    "    w = ((1.0 - prevalence) / prevalence) ** alpha\n",
    "    w = np.clip(w, 1.0, max_w)\n",
    "    return torch.tensor(w, dtype=torch.float)\n",
    "\n",
    "def make_doc_weights(labels_list: List[List[int]], label_weights: np.ndarray, pow_m: float = 0.5) -> np.ndarray:\n",
    "    n = len(labels_list)\n",
    "    doc_w = np.zeros(n, dtype=np.float32)\n",
    "    for i, labs in enumerate(labels_list):\n",
    "        if len(labs) == 0:\n",
    "            doc_w[i] = 1.0\n",
    "        else:\n",
    "            lw = [label_weights[l] for l in labs if 0 <= l < len(label_weights)]\n",
    "            doc_w[i] = max(lw) if lw else 1.0\n",
    "    doc_w = np.power(doc_w, pow_m)\n",
    "    doc_w = doc_w / max(doc_w.mean(), 1e-6)\n",
    "    return doc_w\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Model (unchanged)\n",
    "# ----------------------------\n",
    "class MultiLabelHead(nn.Module):\n",
    "    def __init__(self, backbone_name: str, n_labels: int, dropout: float = 0.2, use_mean_pool: bool = False):\n",
    "        super().__init__()\n",
    "        self.backbone = AutoModel.from_pretrained(backbone_name)\n",
    "        self.hidden = self.backbone.config.hidden_size\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.classifier = nn.Linear(self.hidden, n_labels)\n",
    "        self.use_mean_pool = use_mean_pool\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        out = self.backbone(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        token_emb = out.last_hidden_state if hasattr(out, \"last_hidden_state\") else out[0]\n",
    "        if self.use_mean_pool:\n",
    "            mask = attention_mask.unsqueeze(-1).float()\n",
    "            x = (token_emb * mask).sum(dim=1) / mask.sum(dim=1).clamp_min(1e-6)\n",
    "        else:\n",
    "            x = token_emb[:, 0]  # CLS\n",
    "        logits = self.classifier(self.dropout(x))\n",
    "        return logits\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Optional loss & threshold tuning (unchanged)\n",
    "# ----------------------------\n",
    "class ASLBCE(nn.Module):\n",
    "    def __init__(self, gamma_pos=0.0, gamma_neg=4.0, clip=0.05, reduction=\"mean\"):\n",
    "        super().__init__()\n",
    "        self.gp = gamma_pos\n",
    "        self.gn = gamma_neg\n",
    "        self.clip = clip\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        x = torch.sigmoid(logits)\n",
    "        if self.clip and self.clip > 0:\n",
    "            x = torch.clamp(x - self.clip, min=0.0, max=1.0)\n",
    "        xs_pos = x\n",
    "        xs_neg = 1.0 - x\n",
    "        lossp = - targets * torch.pow(1 - xs_pos, self.gp) * torch.log(xs_pos.clamp_min(1e-8))\n",
    "        lossn = - (1 - targets) * torch.pow(1 - xs_neg, self.gn) * torch.log(xs_neg.clamp_min(1e-8))\n",
    "        loss = lossp + lossn\n",
    "        return loss.mean() if self.reduction == \"mean\" else (loss.sum() if self.reduction == \"sum\" else loss)\n",
    "\n",
    "def tune_thresholds_with_precision(\n",
    "    probs: np.ndarray,\n",
    "    y_true: np.ndarray,\n",
    "    grid: Optional[np.ndarray] = None,\n",
    "    precision_floor: Optional[np.ndarray] = None\n",
    ") -> np.ndarray:\n",
    "    N, L = probs.shape\n",
    "    if grid is None:\n",
    "        grid = np.linspace(0.05, 0.95, 19)\n",
    "    th = np.zeros(L, dtype=np.float32)\n",
    "    for l in range(L):\n",
    "        y = y_true[:, l]; p = probs[:, l]\n",
    "        best_f1, best_t = -1.0, 0.5\n",
    "        for t in grid:\n",
    "            pred = (p >= t).astype(int)\n",
    "            if precision_floor is not None:\n",
    "                prec = precision_score(y, pred, zero_division=0)\n",
    "                if prec < precision_floor[l]:\n",
    "                    continue\n",
    "            f1 = 1.0 if (y.sum()==0 and pred.sum()==0) else f1_score(y, pred, zero_division=0)\n",
    "            if f1 > best_f1:\n",
    "                best_f1, best_t = f1, t\n",
    "        th[l] = best_t\n",
    "    return th\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Aggregation helper\n",
    "# ----------------------------\n",
    "def _aggregate_doc_probs(per_doc_probs: List[List[np.ndarray]],\n",
    "                         per_doc_true: List[List[np.ndarray]],\n",
    "                         agg: str = \"max\") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    agg_fn = np.max if agg == \"max\" else np.mean\n",
    "    probs_doc = np.stack([agg_fn(np.stack(pp, axis=0), axis=0) if len(pp)>0 else np.zeros_like(per_doc_true[0][0])\n",
    "                          for pp in per_doc_probs])\n",
    "    true_doc  = np.stack([tt[0] if len(tt)>0 else np.zeros_like(per_doc_true[0][0]) for tt in per_doc_true])\n",
    "    return probs_doc, true_doc\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Eval helper\n",
    "# ----------------------------\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader, device, logit_adjust=None, *, aggregate: Optional[str] = None, n_docs: Optional[int] = None):\n",
    "    \"\"\"\n",
    "    If aggregate is None: returns stacked chunk-level (or doc-level) probs/true like before.\n",
    "    If aggregate in {\"max\",\"mean\"} and n_docs is provided: aggregates chunk predictions per original document.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    # Chunked document-level path\n",
    "    if aggregate is not None:\n",
    "        assert n_docs is not None, \"n_docs required when using aggregation\"\n",
    "        per_doc_probs: List[List[np.ndarray]] = [[] for _ in range(n_docs)]\n",
    "        per_doc_true:  List[List[np.ndarray]] = [[] for _ in range(n_docs)]\n",
    "\n",
    "        for batch in loader:\n",
    "            ids = batch[\"input_ids\"].to(device)\n",
    "            att = batch[\"attention_mask\"].to(device)\n",
    "            y   = batch[\"labels\"].cpu().numpy()\n",
    "            logits = model(ids, att)\n",
    "            if logit_adjust is not None:\n",
    "                logits = logits - logit_adjust\n",
    "            probs = torch.sigmoid(logits).cpu().numpy()\n",
    "\n",
    "            doc_idx = batch.get(\"doc_index\", None)\n",
    "            if doc_idx is None:\n",
    "                raise ValueError(\"Aggregation requested but no doc_index found in batch.\")\n",
    "            doc_idx = doc_idx.cpu().numpy().tolist()\n",
    "\n",
    "            for p, t, di in zip(probs, y, doc_idx):\n",
    "                per_doc_probs[di].append(p)\n",
    "                per_doc_true[di].append(t)\n",
    "\n",
    "        return _aggregate_doc_probs(per_doc_probs, per_doc_true, agg=aggregate)\n",
    "\n",
    "    # Original (non-aggregated) path\n",
    "    all_probs, all_true = [], []\n",
    "    for batch in loader:\n",
    "        ids = batch[\"input_ids\"].to(device)\n",
    "        att = batch[\"attention_mask\"].to(device)\n",
    "        y   = batch[\"labels\"].cpu().numpy()\n",
    "        logits = model(ids, att)\n",
    "        if logit_adjust is not None:\n",
    "            logits = logits - logit_adjust\n",
    "        probs = torch.sigmoid(logits).cpu().numpy()\n",
    "        all_probs.append(probs)\n",
    "        all_true.append(y)\n",
    "    return np.vstack(all_probs), np.vstack(all_true)\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Training (plain method call; prevalence/weighting selectable)\n",
    "# ----------------------------\n",
    "def train(\n",
    "    train_df: pl.DataFrame,\n",
    "    val_df: pl.DataFrame,\n",
    "    test_df: pl.DataFrame,\n",
    "    *,\n",
    "    out_dir: str = MODEL_DIR / \"supervise_finetune_model\",\n",
    "    backbone: str = \"xlm-roberta-base\",\n",
    "    n_labels: int = 110,\n",
    "    max_len: int = 512,\n",
    "    batch_size: int = 16,\n",
    "    epochs: int = 4,\n",
    "    lr: float = 2e-5,\n",
    "    weight_decay: float = 0.01,\n",
    "    warmup_frac: float = 0.06,\n",
    "    dropout: float = 0.2,\n",
    "    mean_pool: bool = False,\n",
    "    device: Optional[str] = None,\n",
    "    # ---- Imbalance / prevalence toggles ----\n",
    "    use_prevalence: bool = True,\n",
    "    use_pos_weight: bool = True,\n",
    "    use_weighted_sampler: bool = True,\n",
    "    pos_alpha: float = 0.75,\n",
    "    pos_maxw: float = 30.0,\n",
    "    sampler_pow: float = 0.5,\n",
    "    # ---- Logit adjustment & thresholds ----\n",
    "    use_logit_adjust: bool = False,\n",
    "    adjust_in_eval_only: bool = True,\n",
    "    precision_floor_base: float = 0.0,\n",
    "    # ---- Loss choice ----\n",
    "    use_asl: bool = False, asl_gpos: float = 0.0, asl_gneg: float = 4.0, asl_clip: float = 0.05,\n",
    "    # ---- Chunking toggles ----\n",
    "    use_chunking: bool = False,\n",
    "    chunk_size: int = 512,\n",
    "    chunk_stride: int = 64,\n",
    "    agg: str = \"max\",  # \"max\" or \"mean\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Returns: dict with keys: best_ckpt_path, thresholds_path, prevalence_path (optional), metrics\n",
    "    \"\"\"\n",
    "    logger.info(\"Starting training run\")\n",
    "    device = device or (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    Path(out_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    assert {\"text\", \"topic_label\"}.issubset(train_df.columns), \"DataFrames must have columns: text, topic_label\"\n",
    "\n",
    "    # ---- Prevalence ----\n",
    "    need_prev = use_prevalence and (use_pos_weight or use_weighted_sampler or use_logit_adjust or precision_floor_base > 0.0)\n",
    "    train_labels = train_df[\"topic_label\"].to_list()\n",
    "    prevalence = None\n",
    "    if need_prev:\n",
    "        _, prevalence = compute_label_stats(train_labels, n_labels)\n",
    "\n",
    "    # ---- Tokenizer & datasets ----\n",
    "    tok = AutoTokenizer.from_pretrained(backbone)\n",
    "\n",
    "    # Use chunked datasets if requested\n",
    "    train_ds = MultiLabelDataset(\n",
    "        train_df, tok, n_labels=n_labels,\n",
    "        max_len=max_len,\n",
    "        chunk_size=(chunk_size if use_chunking else None),\n",
    "        chunk_stride=(chunk_stride if use_chunking else None),\n",
    "    )\n",
    "    val_ds = MultiLabelDataset(\n",
    "        val_df, tok, n_labels=n_labels,\n",
    "        max_len=max_len,\n",
    "        chunk_size=(chunk_size if use_chunking else None),\n",
    "        chunk_stride=(chunk_stride if use_chunking else None),\n",
    "    )\n",
    "    test_ds = MultiLabelDataset(\n",
    "        test_df, tok, n_labels=n_labels,\n",
    "        max_len=max_len,\n",
    "        chunk_size=(chunk_size if use_chunking else None),\n",
    "        chunk_stride=(chunk_stride if use_chunking else None),\n",
    "    )\n",
    "\n",
    "    # ---- Sampler / loaders ----\n",
    "    if use_weighted_sampler and prevalence is not None:\n",
    "        label_w = (1.0 - prevalence) / prevalence\n",
    "        doc_w = make_doc_weights(train_labels, label_w, pow_m=sampler_pow)\n",
    "\n",
    "        # NEW (chunking): sample weights at the *sample* level if chunking\n",
    "        if getattr(train_ds, \"use_chunking\", False):\n",
    "            sample_w = [float(doc_w[di]) for (di, _ci) in train_ds.index]\n",
    "            weights = torch.tensor(sample_w, dtype=torch.double)\n",
    "            num_samples = len(train_ds)\n",
    "        else:\n",
    "            weights = torch.tensor(doc_w, dtype=torch.double)\n",
    "            num_samples = len(train_ds)\n",
    "\n",
    "        sampler = WeightedRandomSampler(weights=weights, num_samples=num_samples, replacement=True)\n",
    "        shuffle_train = False\n",
    "    else:\n",
    "        sampler = None\n",
    "        shuffle_train = True\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_ds, batch_size=batch_size, sampler=sampler, shuffle=shuffle_train,\n",
    "        collate_fn=lambda b: collate_pad(b, tok.pad_token_id)\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_ds, batch_size=batch_size, shuffle=False,\n",
    "        collate_fn=lambda b: collate_pad(b, tok.pad_token_id)\n",
    "    )\n",
    "    test_loader = DataLoader(\n",
    "        test_ds, batch_size=batch_size, shuffle=False,\n",
    "        collate_fn=lambda b: collate_pad(b, tok.pad_token_id)\n",
    "    )\n",
    "\n",
    "    # ---- Model, loss, optim, sched ----\n",
    "    model = MultiLabelHead(backbone, n_labels=n_labels, dropout=dropout, use_mean_pool=mean_pool).to(device)\n",
    "\n",
    "    if use_asl:\n",
    "        criterion = ASLBCE(gamma_pos=asl_gpos, gamma_neg=asl_gneg, clip=asl_clip)\n",
    "        pos_w_t = None\n",
    "    else:\n",
    "        if use_pos_weight and prevalence is not None:\n",
    "            pos_w_t = make_pos_weights(prevalence, alpha=pos_alpha, max_w=pos_maxw).to(device)\n",
    "        else:\n",
    "            pos_w_t = None\n",
    "        criterion = nn.BCEWithLogitsLoss(pos_weight=pos_w_t)\n",
    "\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    total_steps = len(train_loader) * max(epochs, 1)\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer,\n",
    "        num_warmup_steps=int(warmup_frac * total_steps),\n",
    "        num_training_steps=total_steps\n",
    "    )\n",
    "\n",
    "    # ---- Optional logit adjustment vector ----\n",
    "    logit_adjust_vec = None\n",
    "    if use_logit_adjust and prevalence is not None:\n",
    "        la = np.log(prevalence / (1.0 - prevalence))\n",
    "        logit_adjust_vec = torch.tensor(la, dtype=torch.float, device=device)\n",
    "\n",
    "    best_micro = -1.0\n",
    "    best_ckpt = os.path.join(out_dir, \"best_model.pt\")\n",
    "\n",
    "    # ---- Train loop ----\n",
    "    for ep in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        running = 0.0\n",
    "        for batch in tqdm(train_loader, desc=f\"Epoch {ep}\", leave=False):\n",
    "            ids = batch[\"input_ids\"].to(device)\n",
    "            att = batch[\"attention_mask\"].to(device)\n",
    "            y   = batch[\"labels\"].to(device)\n",
    "\n",
    "            logits = model(ids, att)\n",
    "            if logit_adjust_vec is not None and not adjust_in_eval_only:\n",
    "                logits = logits - logit_adjust_vec\n",
    "\n",
    "            loss = criterion(logits, y)\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            running += loss.item()\n",
    "\n",
    "        # ---- Validation ----\n",
    "        val_probs, val_true = evaluate(\n",
    "            model, val_loader, device,\n",
    "            logit_adjust=(logit_adjust_vec if adjust_in_eval_only else None),\n",
    "            aggregate=(agg if use_chunking else None),      # NEW\n",
    "            n_docs=(len(val_df) if use_chunking else None)  # NEW\n",
    "        )\n",
    "\n",
    "        # Precision floors\n",
    "        if precision_floor_base > 0.0:\n",
    "            if prevalence is not None:\n",
    "                ranks = prevalence.argsort().argsort()\n",
    "                rarity = 1.0 - (ranks / (n_labels - 1 + 1e-8))\n",
    "                floors = (precision_floor_base * rarity).clip(0.0, 0.9)\n",
    "            else:\n",
    "                floors = np.full(n_labels, precision_floor_base, dtype=np.float32)\n",
    "        else:\n",
    "            floors = None\n",
    "\n",
    "        th = tune_thresholds_with_precision(val_probs, val_true, precision_floor=floors)\n",
    "        val_pred = (val_probs >= th).astype(int)\n",
    "        micro = f1_score(val_true, val_pred, average=\"micro\")\n",
    "        macro = f1_score(val_true, val_pred, average=\"macro\")\n",
    "        print(f\"Epoch {ep}/{epochs} - loss {running/len(train_loader):.4f} | micro-F1 {micro:.4f} | macro-F1 {macro:.4f}\")\n",
    "\n",
    "        if micro > best_micro:\n",
    "            best_micro = micro\n",
    "            torch.save(model.state_dict(), best_ckpt)\n",
    "            np.save(os.path.join(out_dir, \"thresholds.npy\"), th)\n",
    "            with open(os.path.join(out_dir, \"backbone.json\"), \"w\") as f:\n",
    "                json.dump({\"backbone\": backbone}, f)\n",
    "            if prevalence is not None:\n",
    "                np.save(os.path.join(out_dir, \"prevalence.npy\"), prevalence)\n",
    "\n",
    "    # ---- Test ----\n",
    "    logger.info(\"Loading best checkpoint for test...\")\n",
    "    model.load_state_dict(torch.load(best_ckpt, map_location=device))\n",
    "    th = np.load(os.path.join(out_dir, \"thresholds.npy\"))\n",
    "    test_probs, test_true = evaluate(\n",
    "        model, test_loader, device,\n",
    "        logit_adjust=(logit_adjust_vec if adjust_in_eval_only else None),\n",
    "        aggregate=(agg if use_chunking else None),          # NEW\n",
    "        n_docs=(len(test_df) if use_chunking else None)     # NEW\n",
    "    )\n",
    "    test_pred = (test_probs >= th).astype(int)\n",
    "    micro = f1_score(test_true, test_pred, average=\"micro\")\n",
    "    macro = f1_score(test_true, test_pred, average=\"macro\")\n",
    "    logger.info(f\"TEST micro-F1 {micro:.4f} | macro-F1 {macro:.4f}\")\n",
    "\n",
    "    prec, rec, f1, support = precision_recall_fscore_support(test_true, test_pred, average=None, zero_division=0)\n",
    "    per_label = {\"precision\": prec.tolist(), \"recall\": rec.tolist(), \"f1\": f1.tolist(), \"support\": support.tolist()}\n",
    "    with open(os.path.join(out_dir, \"per_label_metrics.json\"), \"w\") as f:\n",
    "        json.dump(per_label, f)\n",
    "\n",
    "    return {\n",
    "        \"best_ckpt_path\": best_ckpt,\n",
    "        \"thresholds_path\": os.path.join(out_dir, \"thresholds.npy\"),\n",
    "        \"prevalence_path\": (os.path.join(out_dir, \"prevalence.npy\") if need_prev else None),\n",
    "        \"metrics\": {\"test_micro_f1\": float(micro), \"test_macro_f1\": float(macro)}\n",
    "    }\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Inference helpers\n",
    "# ----------------------------\n",
    "def load_for_inference(out_dir: str, device: Optional[str] = None):\n",
    "    cfg = json.load(open(os.path.join(out_dir, \"backbone.json\")))\n",
    "    backbone = cfg[\"backbone\"]\n",
    "    th = np.load(os.path.join(out_dir, \"thresholds.npy\"))\n",
    "    prev_path = os.path.join(out_dir, \"prevalence.npy\")\n",
    "    prevalence = np.load(prev_path) if os.path.exists(prev_path) else None\n",
    "    tok = AutoTokenizer.from_pretrained(backbone)\n",
    "    model = MultiLabelHead(backbone, n_labels=len(th))\n",
    "    dev = device or (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.load_state_dict(torch.load(os.path.join(out_dir, \"best_model.pt\"), map_location=dev))\n",
    "    model.to(dev).eval()\n",
    "    logit_adjust = None\n",
    "    if prevalence is not None:\n",
    "        logit_adjust = torch.tensor(np.log(prevalence/(1-prevalence)), dtype=torch.float, device=dev)\n",
    "    return tok, model, th, logit_adjust, dev\n",
    "\n",
    "def predict(\n",
    "    texts,\n",
    "    out_dir: str,\n",
    "    device: Optional[str] = None,\n",
    "    max_len: int = 512,\n",
    "    label_names: Optional[List[str]] = None,\n",
    "    top_k: Optional[int] = None,\n",
    "    apply_logit_adjust: bool = True,\n",
    "    threshold_override: Optional[np.ndarray] = None,\n",
    "    # NEW: chunking at inference\n",
    "    use_chunking: bool = False,\n",
    "    chunk_size: int = 512,\n",
    "    chunk_stride: int = 64,\n",
    "    agg: str = \"max\",\n",
    "):\n",
    "    if isinstance(texts, str):\n",
    "        texts = [texts]\n",
    "\n",
    "    tok, model, th, logit_adjust, dev = load_for_inference(out_dir, device=device)\n",
    "    if threshold_override is not None:\n",
    "        th = np.asarray(threshold_override, dtype=np.float32)\n",
    "\n",
    "    outputs = []\n",
    "\n",
    "    if not use_chunking:\n",
    "        enc = tok(texts, padding=True, truncation=True, max_length=max_len, return_tensors=\"pt\")\n",
    "        with torch.no_grad():\n",
    "            logits = model(enc[\"input_ids\"].to(dev), enc[\"attention_mask\"].to(dev))\n",
    "            if apply_logit_adjust and logit_adjust is not None:\n",
    "                logits = logits - logit_adjust\n",
    "            probs = torch.sigmoid(logits).cpu().numpy()\n",
    "\n",
    "        preds_bin = (probs >= th).astype(int)\n",
    "        for i in range(len(texts)):\n",
    "            on_idx = np.where(preds_bin[i] == 1)[0]\n",
    "            active = sorted([(j, float(probs[i, j])) for j in on_idx], key=lambda x: x[1], reverse=True)\n",
    "            sorted_idx = [j for j, _ in active]\n",
    "            item = {\n",
    "                \"text_index\": i,\n",
    "                \"predicted_labels\": [label_names[j] if label_names else j for j in sorted_idx],\n",
    "                \"predicted_probs\": [float(probs[i, j]) for j in sorted_idx],\n",
    "                \"thresholds_used\": [float(th[j]) for j in sorted_idx],\n",
    "            }\n",
    "            if top_k is not None:\n",
    "                order = np.argsort(-probs[i])[:top_k]\n",
    "                item[\"top_k\"] = [\n",
    "                    {\n",
    "                        \"label\": (label_names[j] if label_names else j),\n",
    "                        \"p\": float(probs[i, j]),\n",
    "                        \"t\": float(th[j]),\n",
    "                        \"above_threshold\": bool(probs[i, j] >= th[j]),\n",
    "                    } for j in order\n",
    "                ]\n",
    "            outputs.append(item)\n",
    "        return outputs\n",
    "\n",
    "    # ---- Chunked inference ----\n",
    "    for i, text in enumerate(texts):\n",
    "        enc = tok(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            max_length=chunk_size,\n",
    "            stride=chunk_stride,\n",
    "            return_overflowing_tokens=True,\n",
    "            padding=False\n",
    "        )\n",
    "        n = len(enc[\"input_ids\"])\n",
    "        if n == 0:\n",
    "            # empty fallback\n",
    "            probs_doc = np.zeros_like(th, dtype=np.float32)\n",
    "        else:\n",
    "            # batched over chunks\n",
    "            ids = torch.tensor(enc[\"input_ids\"], dtype=torch.long, device=dev)\n",
    "            att = torch.tensor(enc[\"attention_mask\"], dtype=torch.long, device=dev)\n",
    "            with torch.no_grad():\n",
    "                logits = model(ids, att)\n",
    "                if apply_logit_adjust and logit_adjust is not None:\n",
    "                    logits = logits - logit_adjust\n",
    "                probs_chunks = torch.sigmoid(logits).cpu().numpy()\n",
    "            probs_doc = probs_chunks.max(axis=0) if agg == \"max\" else probs_chunks.mean(axis=0)\n",
    "\n",
    "        preds_bin = (probs_doc >= th).astype(int)\n",
    "        on_idx = np.where(preds_bin == 1)[0]\n",
    "        active = sorted([(j, float(probs_doc[j])) for j in on_idx], key=lambda x: x[1], reverse=True)\n",
    "        sorted_idx = [j for j, _ in active]\n",
    "        item = {\n",
    "            \"text_index\": i,\n",
    "            \"predicted_labels\": [label_names[j] if label_names else j for j in sorted_idx],\n",
    "            \"predicted_probs\": [float(probs_doc[j]) for j in sorted_idx],\n",
    "            \"thresholds_used\": [float(th[j]) for j in sorted_idx],\n",
    "        }\n",
    "        if top_k is not None:\n",
    "            order = np.argsort(-probs_doc)[:top_k]\n",
    "            item[\"top_k\"] = [\n",
    "                {\n",
    "                    \"label\": (label_names[j] if label_names else j),\n",
    "                    \"p\": float(probs_doc[j]),\n",
    "                    \"t\": float(th[j]),\n",
    "                    \"above_threshold\": bool(probs_doc[j] >= th[j]),\n",
    "                } for j in order\n",
    "            ]\n",
    "        outputs.append(item)\n",
    "\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64261c44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-09-03 16:49:42.682\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m298\u001b[0m - \u001b[1mStarting training run\u001b[0m\n",
      "\u001b[32m2025-09-03 16:49:44.751\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m41\u001b[0m - \u001b[1mInitialized MultiLabelDataset (chunking=True)\u001b[0m\n",
      "\u001b[32m2025-09-03 16:49:44.837\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m41\u001b[0m - \u001b[1mInitialized MultiLabelDataset (chunking=True)\u001b[0m\n",
      "\u001b[32m2025-09-03 16:49:44.869\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m41\u001b[0m - \u001b[1mInitialized MultiLabelDataset (chunking=True)\u001b[0m\n",
      "c:\\Users\\povhi\\anaconda3\\envs\\ip\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1 - loss 0.6191 | micro-F1 0.4267 | macro-F1 0.0973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-09-03 16:53:07.058\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m453\u001b[0m - \u001b[1mLoading best checkpoint for test...\u001b[0m\n",
      "c:\\Users\\povhi\\anaconda3\\envs\\ip\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "\u001b[32m2025-09-03 16:53:08.628\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m465\u001b[0m - \u001b[1mTEST micro-F1 0.1102 | macro-F1 0.0224\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "prototype = True\n",
    "tr_path = r'data\\blogs_articles\\train_topics.parquet'\n",
    "va_path = r'data\\blogs_articles\\val_topics.parquet'\n",
    "te_path = r'data\\blogs_articles\\test_topics.parquet'\n",
    "train_df = pl.read_parquet(tr_path)\n",
    "val_df = pl.read_parquet(va_path)\n",
    "test_df = pl.read_parquet(te_path)\n",
    "\n",
    "if prototype:\n",
    "    train_df = train_df.sample(100)\n",
    "    val_df = val_df.sample(10)\n",
    "    test_df = test_df.sample(10)\n",
    "\n",
    "res = train(\n",
    "    train_df = train_df,\n",
    "    val_df = val_df,\n",
    "    test_df = test_df,\n",
    "    out_dir = MODEL_DIR / \"supervise_finetune_model\",\n",
    "    backbone = \"xlm-roberta-base\",\n",
    "    n_labels = 110,\n",
    "    max_len = 512,\n",
    "    batch_size = 16,\n",
    "    epochs = 1,\n",
    "    lr = 2e-5,\n",
    "    weight_decay = 0.01,\n",
    "    warmup_frac = 0.06,\n",
    "    dropout = 0.2,\n",
    "    mean_pool = False,\n",
    "    device = 'cuda',\n",
    "    use_prevalence = False,          \n",
    "    use_pos_weight = False,          \n",
    "    use_weighted_sampler = False,\n",
    "    pos_alpha = 0.75,\n",
    "    pos_maxw = 30.0,\n",
    "    sampler_pow = 0.5,\n",
    "    use_logit_adjust = False,  \n",
    "    adjust_in_eval_only = True,\n",
    "    precision_floor_base = 0.0,\n",
    "    use_asl= False, \n",
    "    asl_gpos = 0.0, \n",
    "    asl_gneg = 4.0, \n",
    "    asl_clip = 0.05,\n",
    "    use_chunking =  True,\n",
    "    chunk_size = 512,\n",
    "    chunk_stride = 64,\n",
    "    agg = \"max\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62778b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3494 [00:00<?, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (1863 > 512). Running this sequence through the model will result in indexing errors\n",
      "100%|██████████| 3494/3494 [00:17<00:00, 202.90it/s]\n"
     ]
    }
   ],
   "source": [
    "combined_df = pl.read_parquet(r'data\\blogs_articles\\combined_parsed_ecb_articles.parquet')\n",
    "dev_df = combined_df.filter(pl.col('filter_type') == 'topic')\n",
    "backbone = \"xlm-roberta-base\"\n",
    "tok = AutoTokenizer.from_pretrained(backbone)\n",
    "\n",
    "token_counts = []\n",
    "for t in tqdm(dev_df[\"text\"].to_list()):\n",
    "    enc = tok(t, truncation=False, padding=False)\n",
    "    token_counts.append(len(enc[\"input_ids\"]))\n",
    "\n",
    "dev_df = dev_df.with_columns(pl.Series(\"token_count\", token_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "edada46f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e = tok('''Lorem ipsum dolor sit amet, consectetur adipiscing elit. Donec in odio non tellus accumsan eleifend eget eget nisl. Morbi vulputate purus ligula, eu ultricies ante mollis id. Vivamus viverra magna vel orci efficitur volutpat. Maecenas dignissim, elit sit amet volutpat convallis, nunc odio cursus enim, vel maximus mauris risus quis dolor. Curabitur justo dolor, scelerisque sit amet scelerisque nec, vehicula vitae mi. Maecenas tincidunt fermentum rhoncus. Praesent molestie vitae libero eu euismod. In consectetur massa vitae quam euismod blandit sit amet ut nisl. Cras sed nisi at elit lobortis faucibus. Ut ac erat non orci sodales auctor non sed ipsum.\n",
    "Nunc et magna et sapien tempus placerat. In convallis vitae enim in rhoncus. Vivamus urna dolor, euismod nec libero non, finibus feugiat leo. Morbi tristique velit libero. Etiam sodales varius nunc vel imperdiet. Fusce eget metus consectetur, convallis purus sed, rhoncus sapien. Maecenas mollis, leo quis tristique lobortis, justo elit ornare neque, a lacinia leo mauris eu purus. Mauris semper consequat elit quis interdum. Curabitur tellus neque, porta vel mi id, placerat tempus augue. Curabitur diam dui, dignissim in rutrum in, elementum quis sapien. Mauris dignissim mattis justo non tempor. Sed nibh ipsum, consectetur dignissim efficitur non, pharetra sed felis. Suspendisse consectetur non quam vitae maximus. Duis scelerisque lacinia nisl et pellentesque.\n",
    "Maecenas ligula turpis, aliquam non eros at, pharetra lobortis velit. Curabitur ut aliquet nulla, in ultricies est. Vivamus vehicula est non lectus laoreet, quis feugiat risus tincidunt. Vestibulum nec augue nunc. Phasellus condimentum turpis fermentum faucibus laoreet. Nunc vestibulum sapien vitae ipsum laoreet pulvinar. Suspendisse ac elit ex. Sed porttitor massa at varius aliquam. Duis mollis est nibh, sit amet tempus leo blandit in. Etiam egestas tellus non consectetur pretium. Nulla risus massa, blandit ac elementum quis, vehicula a dui. Orci varius natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Nunc odio metus, molestie et nisi ac, tincidunt mollis libero.\n",
    "Pellentesque sed quam commodo, pretium sem ac, pharetra mauris. Sed eget ornare orci, eget finibus velit. In feugiat dui vitae laoreet suscipit. Etiam eu mollis tellus. Nam nisi massa, molestie in neque quis, sodales auctor purus. Donec eleifend nulla non enim lacinia, sit amet suscipit nunc facilisis. Sed ut ex non eros sagittis blandit non posuere eros. Sed accumsan hendrerit purus.\n",
    "Quisque diam lorem, fringilla vel nibh dictum, ornare bibendum nisl. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Donec congue risus nec magna lacinia vehicula. Donec cursus nisi neque, eget eleifend ante maximus vel. Sed in vulputate lectus. Donec ante justo, dictum a dui eu, fermentum scelerisque nulla. Nullam fringilla justo vitae ultricies aliquam. Duis semper dapibus nisi a eleifend. Praesent convallis velit velit, ac tincidunt ante consequat et. Duis hendrerit tristique viverra. Quisque et nisi vel ipsum laoreet mattis vel et quam.\n",
    "Cras ornare, purus placerat suscipit vulputate, urna libero convallis quam, non pulvinar orci enim ac erat. Vivamus tincidunt lobortis felis at aliquam. Maecenas lobortis nisi ut metus commodo, nec egestas neque rutrum. Pellentesque venenatis egestas ullamcorper. Donec eget elementum dui, eu lobortis diam. Phasellus arcu velit, porttitor sed neque non, finibus aliquet lorem. Proin in mattis nisi. Pellentesque sagittis nec risus eu posuere. Ut dapibus eros id consequat aliquet. Mauris a sollicitudin mi. Donec elementum dolor vel sapien accumsan, eget aliquet diam hendrerit. Etiam dictum sit amet erat in lacinia. Pellentesque convallis arcu in nibh facilisis efficitur. Nullam interdum lectus sapien, ac luctus lacus laoreet nec. Etiam sit amet aliquet lorem.\n",
    "Morbi bibendum eros ac tortor ornare pulvinar. Sed maximus odio nec accumsan consequat. Pellentesque sit amet justo finibus, congue ipsum tempor, mollis magna. Praesent interdum iaculis mi eget pretium. Proin consequat.\n",
    "''', \n",
    "truncation=True,\n",
    "max_length=512,\n",
    "stride=64,\n",
    "return_overflowing_tokens=True,\n",
    "padding=False,)\n",
    "e['attention_mask'][1]\n",
    "len(e[\"input_ids\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d0d6c0be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:  1599.0446479679451\n",
      "Median:  782.0\n",
      "Std:  2054.6380499911634\n",
      "Max:  17957\n",
      "Min:  2\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.histplot(dev_df['token_count'], bins=100)\n",
    "\n",
    "\n",
    "print('Mean: ', dev_df['token_count'].mean())\n",
    "print('Median: ', dev_df['token_count'].median())\n",
    "print('Std: ', dev_df['token_count'].std())\n",
    "print('Max: ', dev_df['token_count'].max())\n",
    "print('Min: ', dev_df['token_count'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "696118ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (3_494, 18)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>date</th><th>category</th><th>title</th><th>filter_type</th><th>url</th><th>filter_value</th><th>url_hash</th><th>html_downloaded</th><th>download_error</th><th>index</th><th>path_to_html</th><th>text</th><th>error</th><th>authors</th><th>suffix</th><th>filename</th><th>category_base</th><th>token_count</th></tr><tr><td>date</td><td>str</td><td>str</td><td>str</td><td>str</td><td>list[str]</td><td>u64</td><td>bool</td><td>str</td><td>u64</td><td>str</td><td>str</td><td>str</td><td>list[str]</td><td>str</td><td>str</td><td>str</td><td>i64</td></tr></thead><tbody><tr><td>1997-04-25</td><td>&quot;Press release&quot;</td><td>&quot;&quot;EUR&quot; - the new currency code …</td><td>&quot;topic&quot;</td><td>&quot;https://www.ecb.europa.eu/pres…</td><td>[&quot;Central banking&quot;]</td><td>5829553839912007035</td><td>true</td><td>null</td><td>0</td><td>&quot;data\\blogs_articles\\topics_htm…</td><td>&quot;The European Monetary Institut…</td><td>null</td><td>null</td><td>&quot;html&quot;</td><td>&quot;pr970425.en.html&quot;</td><td>&quot;Press release&quot;</td><td>154</td></tr><tr><td>1997-07-01</td><td>&quot;Press release&quot;</td><td>&quot;Change of presidency of the Eu…</td><td>&quot;topic&quot;</td><td>&quot;https://www.ecb.europa.eu/pres…</td><td>[&quot;Central banking&quot;]</td><td>8460861082098867773</td><td>true</td><td>null</td><td>1</td><td>&quot;data\\blogs_articles\\topics_htm…</td><td>&quot;Dr. Willem Frederik Duisenberg…</td><td>null</td><td>null</td><td>&quot;html&quot;</td><td>&quot;pr970701.en.html&quot;</td><td>&quot;Press release&quot;</td><td>84</td></tr><tr><td>1997-07-02</td><td>&quot;Press release&quot;</td><td>&quot;Selection and further developm…</td><td>&quot;topic&quot;</td><td>&quot;https://www.ecb.europa.eu/pres…</td><td>[&quot;Central banking&quot;]</td><td>14802581173913312225</td><td>true</td><td>null</td><td>2</td><td>&quot;data\\blogs_articles\\topics_htm…</td><td>&quot;1. SUMMARY\n",
       "\n",
       "The procedure to s…</td><td>null</td><td>null</td><td>&quot;html&quot;</td><td>&quot;pr970702_1.en.html&quot;</td><td>&quot;Press release&quot;</td><td>1863</td></tr><tr><td>1997-07-02</td><td>&quot;Press release&quot;</td><td>&quot;The EMI&#x27;s mandate with respect…</td><td>&quot;topic&quot;</td><td>&quot;https://www.ecb.europa.eu/pres…</td><td>[&quot;Central banking&quot;]</td><td>12627879612532599931</td><td>true</td><td>null</td><td>3</td><td>&quot;data\\blogs_articles\\topics_htm…</td><td>&quot;Under Article 105a of the Trea…</td><td>null</td><td>null</td><td>&quot;html&quot;</td><td>&quot;pr970702.en.html&quot;</td><td>&quot;Press release&quot;</td><td>571</td></tr><tr><td>1997-07-02</td><td>&quot;Press release&quot;</td><td>&quot;The euro banknotes and the par…</td><td>&quot;topic&quot;</td><td>&quot;https://www.ecb.europa.eu/pres…</td><td>[&quot;Central banking&quot;]</td><td>16592026379229046180</td><td>true</td><td>null</td><td>4</td><td>&quot;data\\blogs_articles\\topics_htm…</td><td>&quot;The EMI considers that it is i…</td><td>null</td><td>null</td><td>&quot;html&quot;</td><td>&quot;pr970702_2.en.html&quot;</td><td>&quot;Press release&quot;</td><td>652</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>2025-07-31</td><td>&quot;The ECB Blog&quot;</td><td>&quot;The ripple effects of monetary…</td><td>&quot;topic&quot;</td><td>&quot;https://www.ecb.europa.eu/pres…</td><td>[&quot;Interest rates&quot;, &quot;Inflation&quot;, &quot;Monetary policy&quot;]</td><td>7248151552685699297</td><td>true</td><td>null</td><td>4780</td><td>&quot;data\\blogs_articles\\topics_htm…</td><td>&quot;Monetary policy has an impact …</td><td>null</td><td>[&quot;Niccolò Battistini&quot;, &quot;Johannes Gareis&quot;]</td><td>&quot;html&quot;</td><td>&quot;ecb.blog20250731~f305d1d4cb.en…</td><td>&quot;The ECB Blog&quot;</td><td>1507</td></tr><tr><td>2025-08-04</td><td>&quot;Economic Bulletin - Article&quot;</td><td>&quot;Cash is alive… and somewhat yo…</td><td>&quot;topic&quot;</td><td>&quot;https://www.ecb.europa.eu/pres…</td><td>[&quot;Monetary policy&quot;]</td><td>15862934961566771934</td><td>true</td><td>null</td><td>4781</td><td>&quot;data\\blogs_articles\\topics_htm…</td><td>&quot;A central puzzle motivating mo…</td><td>null</td><td>[&quot;Rebecca Clipal&quot;, &quot;Alejandro Zamora-Pérez&quot;]</td><td>&quot;html&quot;</td><td>&quot;ecb.ebart202505_03~d74cb56069.…</td><td>&quot;Economic Bulletin&quot;</td><td>6795</td></tr><tr><td>2025-08-04</td><td>&quot;The ECB Blog&quot;</td><td>&quot;Making euro cash fit for the f…</td><td>&quot;topic&quot;</td><td>&quot;https://www.ecb.europa.eu/pres…</td><td>[&quot;Banknotes and coins&quot;, &quot;Digitalisation&quot;]</td><td>6045187915601745579</td><td>true</td><td>null</td><td>4782</td><td>&quot;data\\blogs_articles\\topics_htm…</td><td>&quot;Digital payments are increasin…</td><td>null</td><td>[&quot;Piero Cipollone&quot;]</td><td>&quot;html&quot;</td><td>&quot;ecb.blog20250804~9d3993abe0.en…</td><td>&quot;The ECB Blog&quot;</td><td>2600</td></tr><tr><td>2025-08-05</td><td>&quot;Economic Bulletin - Article&quot;</td><td>&quot;Unveiling the hidden costs of …</td><td>&quot;topic&quot;</td><td>&quot;https://www.ecb.europa.eu/pres…</td><td>[&quot;Monetary policy&quot;]</td><td>3224012719777812433</td><td>true</td><td>null</td><td>4783</td><td>&quot;data\\blogs_articles\\topics_htm…</td><td>&quot;Trade integration, a key drive…</td><td>null</td><td>[&quot;Maria Grazia Attinasi&quot;, &quot;Lukas Boeckelmann&quot;, … &quot;Baptiste Meunier&quot;]</td><td>&quot;html&quot;</td><td>&quot;ecb.ebart202505_01~c93c71e372.…</td><td>&quot;Economic Bulletin&quot;</td><td>7613</td></tr><tr><td>2025-08-07</td><td>&quot;Economic Bulletin - Article&quot;</td><td>&quot;Activity and price discovery i…</td><td>&quot;topic&quot;</td><td>&quot;https://www.ecb.europa.eu/pres…</td><td>[&quot;Monetary policy&quot;]</td><td>17885861729027488798</td><td>true</td><td>null</td><td>4784</td><td>&quot;data\\blogs_articles\\topics_htm…</td><td>&quot;Inflation-linked swap (ILS) ra…</td><td>null</td><td>[&quot;Benjamin Böninghausen&quot;]</td><td>&quot;html&quot;</td><td>&quot;ecb.ebart202505_02~b0c28fc22e.…</td><td>&quot;Economic Bulletin&quot;</td><td>4659</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (3_494, 18)\n",
       "┌────────────┬────────────┬───────────┬───────────┬───┬────────┬───────────┬───────────┬───────────┐\n",
       "│ date       ┆ category   ┆ title     ┆ filter_ty ┆ … ┆ suffix ┆ filename  ┆ category_ ┆ token_cou │\n",
       "│ ---        ┆ ---        ┆ ---       ┆ pe        ┆   ┆ ---    ┆ ---       ┆ base      ┆ nt        │\n",
       "│ date       ┆ str        ┆ str       ┆ ---       ┆   ┆ str    ┆ str       ┆ ---       ┆ ---       │\n",
       "│            ┆            ┆           ┆ str       ┆   ┆        ┆           ┆ str       ┆ i64       │\n",
       "╞════════════╪════════════╪═══════════╪═══════════╪═══╪════════╪═══════════╪═══════════╪═══════════╡\n",
       "│ 1997-04-25 ┆ Press      ┆ \"EUR\" -   ┆ topic     ┆ … ┆ html   ┆ pr970425. ┆ Press     ┆ 154       │\n",
       "│            ┆ release    ┆ the new   ┆           ┆   ┆        ┆ en.html   ┆ release   ┆           │\n",
       "│            ┆            ┆ currency  ┆           ┆   ┆        ┆           ┆           ┆           │\n",
       "│            ┆            ┆ code …    ┆           ┆   ┆        ┆           ┆           ┆           │\n",
       "│ 1997-07-01 ┆ Press      ┆ Change of ┆ topic     ┆ … ┆ html   ┆ pr970701. ┆ Press     ┆ 84        │\n",
       "│            ┆ release    ┆ presidenc ┆           ┆   ┆        ┆ en.html   ┆ release   ┆           │\n",
       "│            ┆            ┆ y of the  ┆           ┆   ┆        ┆           ┆           ┆           │\n",
       "│            ┆            ┆ Eu…       ┆           ┆   ┆        ┆           ┆           ┆           │\n",
       "│ 1997-07-02 ┆ Press      ┆ Selection ┆ topic     ┆ … ┆ html   ┆ pr970702_ ┆ Press     ┆ 1863      │\n",
       "│            ┆ release    ┆ and       ┆           ┆   ┆        ┆ 1.en.html ┆ release   ┆           │\n",
       "│            ┆            ┆ further   ┆           ┆   ┆        ┆           ┆           ┆           │\n",
       "│            ┆            ┆ developm… ┆           ┆   ┆        ┆           ┆           ┆           │\n",
       "│ 1997-07-02 ┆ Press      ┆ The EMI's ┆ topic     ┆ … ┆ html   ┆ pr970702. ┆ Press     ┆ 571       │\n",
       "│            ┆ release    ┆ mandate   ┆           ┆   ┆        ┆ en.html   ┆ release   ┆           │\n",
       "│            ┆            ┆ with      ┆           ┆   ┆        ┆           ┆           ┆           │\n",
       "│            ┆            ┆ respect…  ┆           ┆   ┆        ┆           ┆           ┆           │\n",
       "│ 1997-07-02 ┆ Press      ┆ The euro  ┆ topic     ┆ … ┆ html   ┆ pr970702_ ┆ Press     ┆ 652       │\n",
       "│            ┆ release    ┆ banknotes ┆           ┆   ┆        ┆ 2.en.html ┆ release   ┆           │\n",
       "│            ┆            ┆ and the   ┆           ┆   ┆        ┆           ┆           ┆           │\n",
       "│            ┆            ┆ par…      ┆           ┆   ┆        ┆           ┆           ┆           │\n",
       "│ …          ┆ …          ┆ …         ┆ …         ┆ … ┆ …      ┆ …         ┆ …         ┆ …         │\n",
       "│ 2025-07-31 ┆ The ECB    ┆ The       ┆ topic     ┆ … ┆ html   ┆ ecb.blog2 ┆ The ECB   ┆ 1507      │\n",
       "│            ┆ Blog       ┆ ripple    ┆           ┆   ┆        ┆ 0250731~f ┆ Blog      ┆           │\n",
       "│            ┆            ┆ effects   ┆           ┆   ┆        ┆ 305d1d4cb ┆           ┆           │\n",
       "│            ┆            ┆ of        ┆           ┆   ┆        ┆ .en…      ┆           ┆           │\n",
       "│            ┆            ┆ monetary… ┆           ┆   ┆        ┆           ┆           ┆           │\n",
       "│ 2025-08-04 ┆ Economic   ┆ Cash is   ┆ topic     ┆ … ┆ html   ┆ ecb.ebart ┆ Economic  ┆ 6795      │\n",
       "│            ┆ Bulletin - ┆ alive…    ┆           ┆   ┆        ┆ 202505_03 ┆ Bulletin  ┆           │\n",
       "│            ┆ Article    ┆ and       ┆           ┆   ┆        ┆ ~d74cb560 ┆           ┆           │\n",
       "│            ┆            ┆ somewhat  ┆           ┆   ┆        ┆ 69.…      ┆           ┆           │\n",
       "│            ┆            ┆ yo…       ┆           ┆   ┆        ┆           ┆           ┆           │\n",
       "│ 2025-08-04 ┆ The ECB    ┆ Making    ┆ topic     ┆ … ┆ html   ┆ ecb.blog2 ┆ The ECB   ┆ 2600      │\n",
       "│            ┆ Blog       ┆ euro cash ┆           ┆   ┆        ┆ 0250804~9 ┆ Blog      ┆           │\n",
       "│            ┆            ┆ fit for   ┆           ┆   ┆        ┆ d3993abe0 ┆           ┆           │\n",
       "│            ┆            ┆ the f…    ┆           ┆   ┆        ┆ .en…      ┆           ┆           │\n",
       "│ 2025-08-05 ┆ Economic   ┆ Unveiling ┆ topic     ┆ … ┆ html   ┆ ecb.ebart ┆ Economic  ┆ 7613      │\n",
       "│            ┆ Bulletin - ┆ the       ┆           ┆   ┆        ┆ 202505_01 ┆ Bulletin  ┆           │\n",
       "│            ┆ Article    ┆ hidden    ┆           ┆   ┆        ┆ ~c93c71e3 ┆           ┆           │\n",
       "│            ┆            ┆ costs of  ┆           ┆   ┆        ┆ 72.…      ┆           ┆           │\n",
       "│            ┆            ┆ …         ┆           ┆   ┆        ┆           ┆           ┆           │\n",
       "│ 2025-08-07 ┆ Economic   ┆ Activity  ┆ topic     ┆ … ┆ html   ┆ ecb.ebart ┆ Economic  ┆ 4659      │\n",
       "│            ┆ Bulletin - ┆ and price ┆           ┆   ┆        ┆ 202505_02 ┆ Bulletin  ┆           │\n",
       "│            ┆ Article    ┆ discovery ┆           ┆   ┆        ┆ ~b0c28fc2 ┆           ┆           │\n",
       "│            ┆            ┆ i…        ┆           ┆   ┆        ┆ 2e.…      ┆           ┆           │\n",
       "└────────────┴────────────┴───────────┴───────────┴───┴────────┴───────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ip",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
